In this paper, the authors study learning problems in which the model of ultimate interest depends on other quantities of no direct interest but that need to be estimated first - so-called nuisance components, and the problem of estimating treatment effects or learning policies from observational data is a clear example: nuisance components include propensities and outcome models, which are necessary for debiasing predictions; errors in estimating these models corrupt the final target model. The authors provide a simple, general recipe for ensuring that the final model is robust to such errors, and provide non-asymptotic guarantees, which is achieved through a two-stage, sample-splitting meta-algorithm.
First, the nuisance functions are estimated on one split of the data, using any modern ML method of choice, and second, the nuisance functions are plugged into a specially constructed, orthogonal loss, and the target model is learned on the other split of the data.
Orthogonality, which builds on Neyman's insight, ensures that the loss function is designed so that small errors in the nuisance estimates do not result in first-order bias in the target learning step, and as a result, the nuisance error affects the final excess risk only at higher order.
The authors consider two regimes: in the fast-rate regime, where the loss has curvature with respect to predictions, they show that the same rates can be achieved as if the nuisance were known, as long as the nuisance is estimated fairly well, and in the slow-rate regime, where such curvature is absent, they show that robustness still obtains, but the dependence on nuisance error is slightly weaker.
In both regimes, orthogonality turns what would otherwise be a linear sensitivity to nuisance error into a higher-order one, which makes oracle-style performance possible without requiring perfect nuisance estimation, and the paper's model-agnosticism is also a key strength, because the guarantees depend only on black-box performance bounds for the nuisance and target learners, so the method can be used with neural networks, kernels, random forests, or high-dimensional linear models.
The theorems are non-asymptotic and allow for misspecification, so it is not necessary that the "true" model lies in the class of models to get strong prediction guarantees, and the authors give complexity-based conditions, via metric entropy and other related tools, under which oracle rates are possible for rich, nonparametric classes.
The authors instantiate the framework across a number of key applications: heterogeneous treatment effect estimation, offline policy optimization, domain adaptation and sample bias correction, learning with missing data, and they discuss two common loss constructions: the residualized loss which has been used in R-learners, and a doubly robust loss that combines outcome regression with inverse propensity weighting; both satisfy orthogonality and show how coverage/overlap or propensity bounds enter only in higher order terms.
Beyond the meta-theory, the authors also study practical algorithms such as plug-in ERM and variance-penalized ERM under the framework of this paper, and show how to adapt classical learning-theoretic tools to account for nuisance estimation while preserving sharp rates.
Estimate nuisances flexibly, use sample splitting, optimize an orthogonal loss, which yields robust, distribution dependent excess risk guarantees that allow modern ML methods to be used safely in causal and decision-making tasks.
